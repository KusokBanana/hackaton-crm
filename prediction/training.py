# -*- coding: utf-8 -*-
"""Нейронка хак

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JnHgQVNLKXQbPy89owUPZsDwJvVjpPhU
"""

!pip install seaborn

import pathlib

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
import numpy as np


print(tf.__version__)

"""### Получите данные
Сперва загрузим датасет.
"""

# dataset_path = keras.utils.get_file("auto-mpg.data", "http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data")
dataset_path = "clients_new (2).csv"
# dataset_path = "clients1.csv"
dataset_path

"""Импортируем его при помощи библиотеки Pandas:"""

column_names = ["client_id","age","gender_code","directory","amrg_eop","acsh_eop","acrd_eop","pcur_eop","pcrd_eop","psav_eop","pdep_eop","swork_s","tpos_s","retail_cost","auto_cost","calls_cost","communal_cost","gos_cost","personal_cost","shops_cost","rent_cost","contract_cost","transport_cost","building_cost","prof_cost","business_cost","constributions_cost","avia_cost","vendors_cost","hotels_cost","pleasure_cost","finance_cost","other_cost","transactions_count","clothes_cost","auto_count","calls_count","communal_count","gos_count","personal_count","shops_count","clothes_count","rent_count","contract_count","transport_count","building_count","prof_count","business_count","constributions_count","avia_count","vendors_count","hotels_count","pleasure_count","finance_count","other_count","retail_count"]
# column_names = ['client_id','age','gender_code','directory','aMRG_eop','aCSH_eop','aCRD_eop','pCUR_eop','pCRD_eop','pSAV_eop','pDEP_eop','sWork_S','tPOS_S']
raw_dataset = pd.read_csv(dataset_path, names=column_names, header=1, # decimal = ",", 
                          na_values="?", comment='\t',skipinitialspace=True, index_col="client_id") 


# Выпиливаем ID
# raw_dataset.pop('client_id')
# Выпиливаем город пока что
directory = raw_dataset.pop('directory')

dataset = raw_dataset.copy()
dataset.tail()

dataset.isna().sum()
dataset = dataset.dropna()

"""Работа с возрастом"""

gender = dataset.pop('gender_code')
dataset['gender'] = (gender == "М")* 1.0

"""Конвертирую долги в бинарные признаки"""

ipoteka = dataset.pop('amrg_eop')
credcard = dataset.pop('acrd_eop')
loan = dataset.pop('acsh_eop')
dataset['ipoteka'] = (ipoteka > 0)* 1.0
dataset['credcard'] = (credcard > 0)* 1.0
dataset['loan'] = (loan > 0)* 1.0

"""Вид датасета после преобразований"""

fullds = dataset.copy()
dataset.drop(dataset.tail(2).index,inplace=True)
dataset.tail()

predict = ["ipoteka", "credcard", "loan"]
train_dataset = {}
test_dataset = {}
train_stats = {}
for item in predict:
  ds = dataset.copy()
  train_dataset[item] = ds.sample(frac=0.8,random_state=0)
  test_dataset[item] = ds.drop(train_dataset[item].index)
  ts = train_dataset[item].describe()
  ts.pop(item)
  train_stats[item] = ts.transpose()
train_stats[item]

"""### Выпиливаем метки"""

# train_labels = train_dataset.pop(predict)
# test_labels = test_dataset.pop(predict)
train_labels = {}
test_labels = {}
for item in predict:
  train_labels[item] = train_dataset[item].pop(item)
  test_labels[item] = test_dataset[item].pop(item)
train_dataset[item].tail()

"""### Нормализация"""

train_dataset[item].gender.unique()

def norm(x, item):
  ts = train_stats[item]
  return (x - ts['mean']) / ts['std']
normed_train_data = {}
normed_test_data = {}
for item in predict:
  normed_train_data[item] = norm(train_dataset[item], item)
  normed_test_data[item] = norm(test_dataset[item], item)

"""## Модель"""

def build_model(item):
  model = keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=[len(train_dataset[item].keys())]),
    layers.Dense(128, activation='relu'),
    layers.Dense(128, activation='relu'),
    layers.Dense(1, activation='sigmoid')
  ])

  optimizer = tf.keras.optimizers.RMSprop(0.001)

  model.compile(loss='mse',
                optimizer=optimizer,
                metrics=['mae', 'mse'])
  return model

models = {}
for item in predict:
  models[item] = build_model(item)

# model.summary()

"""Тест модели"""

testitem = predict[0]
example_batch = normed_train_data[testitem][:10]
example_batch

example_result = models[testitem].predict(example_batch)
example_result

"""### Предсказание до обучения"""

for item in predict:
  loss, mae, mse = models[item].evaluate(normed_test_data[item], test_labels[item], verbose=2)
  print("Testing set Mean Abs Error for "+item+" : {:5.2f}%".format(mae*100))



"""### Обучение"""

# Выведем прогресс обучения в виде точек после каждой завершенной эпохи
class PrintDot(keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs):
    if epoch % 100 == 0: print('')
    print('.', end='')

EPOCHS = 200
history = {}

for item in predict:
  # print(normed_train_data[item], train_labels[item])
  print("\nTraining ", item)
  history[item] = models[item].fit(
    normed_train_data[item], train_labels[item],
    epochs=EPOCHS, validation_split = 0.2, verbose=0,
    callbacks=[PrintDot()])
# early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)
# history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,
#                     validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

"""Визуализируйте процесс обучения модели используя статистику содержащуюся в объекте `history`."""

for item in predict:
  hist = pd.DataFrame(history[item].history)
  hist['epoch'] = history[item].epoch
  print(hist.tail())

def plot_history(history, item):
  hist = pd.DataFrame(history.history)
  hist['epoch'] = history.epoch

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('Mean Abs Error [%s]' % item)
  plt.plot(hist['epoch'], hist['mae'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mae'],
           label = 'Val Error')
  # plt.ylim([0,5])
  plt.legend()

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('Mean Square Error [$%s^2$]' % item)
  plt.plot(hist['epoch'], hist['mse'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mse'],
           label = 'Val Error')
  # plt.ylim([0,20])
  plt.legend()
  plt.show()

for item in predict:
  plot_history(history[item], item)

"""### Переучиваем с ограничением эпох"""

early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)
for item in predict:
  models[item] = build_model(item)
  print("\nTraining ", item)
  history[item] = models[item].fit(
    normed_train_data[item], train_labels[item],
    epochs=EPOCHS, validation_split = 0.2, verbose=0,
    callbacks=[early_stop, PrintDot()]) 
  plot_history(history[item], item)

for item in predict:
  loss, mae, mse = models[item].evaluate(normed_test_data[item], test_labels[item], verbose=2)
  print("Testing set Mean Abs Error for "+item+" : {:5.2f}%".format(mae*100))

"""### Прогноз"""

test_predictions = {}
for item in predict:
  test_predictions[item] = models[item].predict(normed_test_data[item]).flatten()
  # print(test_predictions)

for item in predict:
  plt.figure()
  plt.scatter(test_labels[item], test_predictions[item])
  plt.xlabel('Истинные [%s]' % item)
  plt.ylabel('Predictions [%s]' % item)
  plt.axis('equal')
  plt.axis('square')
  plt.xlim([0,plt.xlim()[1]])
  plt.ylim([0,plt.ylim()[1]])
  _ = plt.plot([-0, 0], [-1, 1])

for item in predict:
  error = test_predictions[item] - test_labels[item]
  plt.figure()
  plt.hist(error, bins = 100)
  plt.xlabel("Ошибка предсказания %s"%item)
  _ = plt.ylabel("Count")

"""Тест на себе"""

me = fullds[999:]
for item in predict:
  metest = me.copy()
  metest.pop(item)
  normed = norm(metest, item)
  
  # print(normed)
  pred = models[item].predict(normed).flatten()
  print("Chance of %s is" % (item))
  print(pred)

"""Предсказание всего датасета и сохранение"""

for item in predict:
  ds = fullds.copy()
  ds.pop(item)
  normed = norm(ds, item)
  pred = models[item].predict(normed)
  pred.tofile("predict_%s.csv" % item, sep='\n',format='%7.6f')
  # np.savetxt("predict_%s.csv" % item, pred, delimiter=",")

"""Сохранение модели"""

for item in predict:
  models[item].save("model_%s.h5"%item)